# 障害のシナリオ

この記事ではFluentdの様々な障害シナリオを紹介します。ここではFluentdはローカルに *forwarders* を持っており、すべてのログが複数の *aggregators* に集約される、 [高可用性設定](high-availability)になっていることを前提としています。

## アプリがForwarderにレコードを送れない場合

様々な言語でLoggerライブラリを使用する際の障害のシナリオとして、アプリケーションからローカルのFluentdインスタンスにレコードを送れなくなる場合があります。各Loggerライブラリの成熟度に応じて、データの消失を防ぐためにいくつかの巧みなメカニズムが実装されています。

#### 1) メモリバッファ ([Ruby](ruby), [Java](java), [Python](python), [Perl](perl) で使用可能)

送信先のFluentdインスタンスがダウンした場合、特定のLoggerの実装では、受け取ったログを保持するためにより多くのメモリを使用します。Fluentdが回復したとき、これらのLoggerは自動的にFluentdにバッファされたログを送ります。メモリバッファの最大サイズに達した場合、現在の多くの実装ではデータをディスクに書き込むか、またはログを破棄します。

#### 2) 指数関数的バックオフ ([Ruby](ruby), [Java](java) で使用可能)

ローカルforwarderにログを再送信しようとした際、いくつかの実装では過度の再接続要求を防ぐために指数関数的バックオフを使用します。

## ForwarderまたはAggregatorのFluentdがダウンした場合

Fluentdのプロセスが何らかの理由でダウンした場合はどうなるのでしょうか?それはバッファの設定に依存します。

#### buf_memory

もし[buf_memory](buf_memory)を使っている場合、バッファされたデータは完全に失われます。これはパフォーマンスをより高くするためのトレードオフです。 flush_interval を下げるとデータを失う可能性は減りますが、forwarderとaggregatorの間の転送回数が増えます。

#### buf_file

もし[buf_file](buf_file)を使っている場合、バッファされたデータはディスク上に格納されます。Fluentdが回復したあと、送信先にバッファされたデータの再送を試みます。

バッファファイルがI/Oエラーによって壊れている場合にはデータが失われることに注意してください。ディスクに空き容量が無い場合にも、データを保存することができないためデータが失われます。

## 格納先がダウンした場合

保存先(例: Amazon S3, MongoDB, HDFS, etc.)がダウンした場合、Fluentdはバッファされたデータを再送しようとし続けます。再試行のロジックはプラグインの実装に依存します。

もし[buf_memory](buf_memory)を使っている場合、aggregatorはバッファの制限に達すると新しいログの受け入れを停止します。[buf_file](buf_file)を使っている場合には、aggregatorはディスクスペースを使い果たすまでログを受け入れ続けます。
